\title{Metrics}{metrics}

\use-plugin{concourse-docs}

Metrics are essential in understanding how any large system is behaving and
performing. Concourse can emit metrics about both the system health itself and
about the builds that it is running. Operators can tap into these metrics in
order to observe the health of the system.

In the spirit of openness, the \link{metrics from our
deployment}{https://metrics.concourse-ci.org/dashboard/db/concourse} are
public. We consider it a bug to emit anything sensitive or secret into our
metrics pipeline.

\section{
  \title{Configuring Metrics}

  The \reference{web-node} can be configured to emit metrics on start.

  Currently supported metrics emitters are InfluxDB, NewRelic, Prometheus, Datadog, and
  Riemann. There is also a dummy emitter that will just spit the metrics out in
  to the logs at \code{DEBUG} level, which can be enabled with the
  \code{--emit-to-logs} flag.

  There are various flags for different emitters; run \code{concourse web
  --help} and look for "Metric Emitter" to see what's available.
}

\section{
  \title{What's emitted?}

  This reference section lists of all of the metrics that Concourse emits. We
  don't include the warning and critical levels as they will keep changing as
  we optimise the system. To find those, please refer to the source of truth:
  \link{the code}{https://github.com/concourse/concourse/blob/master/atc/metric/metrics.go}.

  \define-metric{scheduling: full duration (ms)}{
    This is the time taken (in milliseconds) to schedule an entire pipeline
    including the time taken to load the version information from the database
    and calculate the latest valid versions for each job.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{pipeline}
      }{
        The pipeline which was being scheduled.
      }
    }
  }

  \define-metric{scheduling: loading versions duration (ms)}{
    This is the time taken (in milliseconds) to load the version information
    from the database.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{pipeline}
      }{
        The pipeline which was being scheduled.
      }
    }
  }

  \define-metric{scheduling: job duration (ms)}{
    This is the time taken (in milliseconds) to calculate the set of valid
    input versions when scheduling a job. It is emitted once for each job per
    pipeline scheduling tick.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{pipeline}
      }{
        The pipeline which was being scheduled.
      }
    }{
      \definition{
        \code{job}
      }{
        The job which was being scheduled.
      }
    }
  }

  \define-metric{worker containers}{
    The number of containers that are currently running on your workers.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{worker}
      }{
        The name of the worker.
      }
    }
  }

  \define-metric{worker volumes}{
    The number of volumes that are currently present on your workers.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{worker}
      }{
        The name of the worker.
      }
    }
  }

  \define-metric{build started}{
    This event is emitted when a build starts. Its value is the build ID of the
    build. However, it is most useful for annotating your metrics with the
    start and end of different jobs.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{pipeline}
      }{
        The pipeline which contains the build being started.
      }
    }{
      \definition{
        \code{job}
      }{
        The job which configured the build being started.
      }
    }{
      \definition{
        \code{build_name}
      }{
        The name of the build being started. (Remember that build numbers in
        Concourse are actually names and are strings).
      }
    }{
      \definition{
        \code{build_id}
      }{
        The ID of the build being started.
      }
    }
  }

  \define-metric{build finished}{
    This event is emitted when a build ends. Its value is the duration of the
    build in milliseconds. You can use this metric in conjunction with
    \code{build started} to annotate your metrics with when builds started and
    stopped.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{pipeline}
      }{
        The pipeline which contains the build that finished.
      }
    }{
      \definition{
        \code{job}
      }{
        The job which configured the build that finished.
      }
    }{
      \definition{
        \code{build_name}
      }{
        The name of the build that finished. (Remember that build numbers in
        Concourse are actually names and are strings).
      }
    }{
      \definition{
        \code{build_id}
      }{
        The ID of the build that finished.
      }
    }{
      \definition{
        \code{build_status}
      }{
        The resulting status of the build; one of "succeeded", "failed",
        "errored", or "aborted".
      }
    }
  }

  \define-metric{http response time}{
    This metric is emitted for each HTTP request to an ATC (both API and web
    requests). It contains the duration (in milliseconds) for each request and
    is useful for finding slow requests.

    \larger{Attributes}
    \definitions{
      \definition{
        \code{route}
      }{
        The route which the HTTP request matched. i.e. /builds/:id
      }
    }{
      \definition{
        \code{path}
      }{
        The literal path of the HTTP request. i.e. /builds/1234
      }
    }
  }
}
