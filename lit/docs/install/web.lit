\title{\aux{Running a }\code{web} node}{concourse-web}{web-node}

\use-plugin{concourse-docs}
\omit-children-from-table-of-contents

The \code{web} node is responsible for running the web UI, API, and as well
as performing all pipeline scheduling. It's basically the brain of Concourse.

\section{
  \title{Prerequisites}{web-prerequisites}

  Nothing special - the \code{web} node is a pretty simple Go application that
  can be run like a 12-factor app.
}

\section{
  \title{Running}{web-running}

  The \code{concourse} CLI can run as a \code{web} node via the \code{web}
  subcommand.

  Before running it, let's configure a local user so we can log in:

  \codeblock{bash}{{{
  CONCOURSE_ADD_LOCAL_USER=myuser:mypass
  CONCOURSE_MAIN_TEAM_LOCAL_USER=myuser
  }}}

  This will configure a single user, \code{myuser}, with the password
  \code{mypass}. You'll probably want to change those to sensible values, and
  later you may want to configure a proper auth provider - check out
  \reference{auth} whenever you're ready.

  Next, you'll need to configure the session signing key, the SSH key for the
  worker gateway, and the authorized worker key. Check
  \reference{generating-keys} to learn what these are and how they are created.

  \codeblock{bash}{{{
  CONCOURSE_SESSION_SIGNING_KEY=path/to/session_signing_key
  CONCOURSE_TSA_HOST_KEY=path/to/tsa_host_key
  CONCOURSE_TSA_AUTHORIZED_KEYS=path/to/authorized_worker_keys
  }}}

  Finally, \code{web} needs to know how to reach your Postgres database. This
  can be set like so:

  \codeblock{bash}{{{
  CONCOURSE_POSTGRES_HOST=127.0.0.1 # default
  CONCOURSE_POSTGRES_PORT=5432      # default
  CONCOURSE_POSTGRES_DATABASE=atc   # default
  CONCOURSE_POSTGRES_USER=my-user
  CONCOURSE_POSTGRES_PASSWORD=my-password
  }}}

  If you're running PostgreSQL locally, you can probably just point it to the
  socket and rely on the \code{peer} auth:

  \codeblock{bash}{{{
  CONCOURSE_POSTGRES_SOCKET=/var/run/postgresql
  }}}

  Now that everything's set, run:

  \codeblock{bash}{{{
  concourse web
  }}}
}

\section{
  \title{Properties}{web-properties}

  CPU usage: peaks during pipeline scheduling, primarily when scheduling
  \reference{pipeline-jobs}. Mitigated by adding more \code{web} nodes. In this
  regard, \code{web} nodes can be considered compute-heavy more than anything
  else at large scale.

  Memory usage: not very well classified at the moment as it's not generally a
  concern. Give it a few gigabytes and keep an eye on it.

  Disk usage: none

  Bandwidth usage: aside from handling external traffic, the \code{web} node
  will at times have to stream bits out from one worker and into another while
  executing \reference{steps}.

  Highly available: yes; \code{web} nodes can all be configured the same (aside
  from \code{--peer-url}) and placed behind a load balancer. Periodic tasks
  like garbage-collection will not be duplicated for each node.

  Horizontally scalable: yes; they will coordinate workloads using the
  database, resulting in less work for each node and thus lower CPU usage.

  Outbound traffic:

  \list{
    \code{db} on its configured port for persistence
  }{
    \code{db} on its configured port for locking and coordinating in a
    multi-\code{web} node deployment
  }{
    directly-registered \code{worker} nodes on ports \code{7777}, \code{7788},
    and \code{7799} for checking \reference{pipeline-resources}, executing
    builds, and performing garbage-collection
  }{
    other \code{web} nodes (possibly itself) on an ephemeral port when a worker
    is forwarded through the web node's TSA
  }

  Inbound traffic:

  \list{
    \code{worker} connects to the TSA on port \code{2222} for registration
  }{
    \code{worker} downloads inputs from the ATC during \reference{fly-execute}
    via its external URL
  }{
    external traffic to the ATC API via the web UI and \reference{fly-cli}
  }

}

\section{
  \title{Operation}{web-operation}

  The \reference{web-node} can be scaled up for high availability, and
  they'll also roughly share their scheduling workloads, using the database
  to synchronize. This is done by just running more \code{web} commands on
  different machines, and optionally putting them behind a load balancer.

  To run a cluster of \reference{web-node}s, you'll first need to ensure
  they're all pointing to the same PostgreSQL server.

  Next, you'll need to configure a \italic{peer URL}. This is a URL that can be
  used to reach this \code{web} node's web server from other \code{web} nodes.
  Typically this uses a private IP, like so:

  \codeblock{bash}{{{
  CONCOURSE_PEER_URL=http://10.10.0.1:8080
  }}}

  Finally, if all of these nodes are going to be accessed through a load
  balancer, you'll need to configure the external URL that will be used to
  reach your Concourse cluster:

  \codeblock{bash}{{{
  CONCOURSE_EXTERNAL_URL=https://ci.example.com
  }}}

  Aside from the peer URL, all configuration must be consistent across all
  \code{web} nodes in the cluster to ensure consistent results.
}
